<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<meta name=author content="Geert Litjens">
<meta name=description content="Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer-aided applications of breast MRI. Traditional image analysis and computer vision techniques, such atlas, template matching, or, edge and surface detection, have been applied to solve this task. However, applicability of these methods is usually limited by the characteristics of the images used in the study datasets, while breast MRI varies with respect to the different MRI protocols used, in addition to the variability in breast shapes. All this variability, in addition to various MRI artifacts, makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore, in this study, we investigated the use of a deep-learning approach known as &#34;U-net.&#34; We used a dataset of 66 breast MRI's randomly selected from our scientific archive, which includes five different MRI acquisition protocols and breasts from four breast density categories in a balanced distribution. To prepare reference segmentations, we manually segmented breast and FGT for all images using an in-house developed workstation. We experimented with the application of U-net in two different ways for breast and FGT segmentation. In the first method, following the same pipeline used in traditional approaches, we trained two consecutive (2C) U-nets: first for segmenting the breast in the whole MRI volume and the second for segmenting FGT inside the segmented breast. In the second method, we used a single 3-class (3C) U-net, which performs both tasks simultaneously by segmenting the volume into three regions: nonbreast, fat inside the breast, and FGT inside the breast. For comparison, we applied two existing and published methods to our dataset: an atlas-based method and a sheetness-based method. We used Dice Similarity Coefficient (DSC) to measure the performances of the automated methods, with respect to the manual segmentations. Additionally, we computed Pearson's correlation between the breast density values computed based on manual and automated segmentations. The average DSC values for breast segmentation were 0.933, 0.944, 0.863, and 0.848 obtained from 3C U-net, 2C U-nets, atlas-based method, and sheetness-based method, respectively. The average DSC values for FGT segmentation obtained from 3C U-net, 2C U-nets, and atlas-based methods were 0.850, 0.811, and 0.671, respectively. The correlation between breast density values based on 3C U-net and manual segmentations was 0.974. This value was significantly higher than 0.957 as obtained from 2C U-nets (P < 0.0001, Steiger's Z-test with Bonferoni correction) and 0.938 as obtained from atlas-based method (P = 0.0016). In conclusion, we applied a deep-learning method, U-net, for segmenting breast and FGT in MRI in a dataset that includes a variety of MRI protocols and breast densities. Our results showed that U-net-based methods significantly outperformed the existing algorithms and resulted in significantly more accurate breast density computation.">
<link rel=alternate hreflang=en-us href=https://geertlitjens.nl/publication/dalm-17/>
<meta name=theme-color content="hsl(339, 90%, 68%)">
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/vs2015.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/vs2015.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=/css/wowchemy.7d86dc42c902b14610813b0603567dae.css>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139145569-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','UA-139145569-1',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://geertlitjens.nl/publication/dalm-17/>
<meta property="twitter:card" content="summary">
<meta property="twitter:site" content="@GeertLitjens">
<meta property="twitter:creator" content="@GeertLitjens">
<meta property="og:site_name" content="Geert Litjens">
<meta property="og:url" content="https://geertlitjens.nl/publication/dalm-17/">
<meta property="og:title" content="Using deep learning to segment breast and fibroglandular tissue in MRI volumes | Geert Litjens">
<meta property="og:description" content="Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer-aided applications of breast MRI. Traditional image analysis and computer vision techniques, such atlas, template matching, or, edge and surface detection, have been applied to solve this task. However, applicability of these methods is usually limited by the characteristics of the images used in the study datasets, while breast MRI varies with respect to the different MRI protocols used, in addition to the variability in breast shapes. All this variability, in addition to various MRI artifacts, makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore, in this study, we investigated the use of a deep-learning approach known as &#34;U-net.&#34; We used a dataset of 66 breast MRI's randomly selected from our scientific archive, which includes five different MRI acquisition protocols and breasts from four breast density categories in a balanced distribution. To prepare reference segmentations, we manually segmented breast and FGT for all images using an in-house developed workstation. We experimented with the application of U-net in two different ways for breast and FGT segmentation. In the first method, following the same pipeline used in traditional approaches, we trained two consecutive (2C) U-nets: first for segmenting the breast in the whole MRI volume and the second for segmenting FGT inside the segmented breast. In the second method, we used a single 3-class (3C) U-net, which performs both tasks simultaneously by segmenting the volume into three regions: nonbreast, fat inside the breast, and FGT inside the breast. For comparison, we applied two existing and published methods to our dataset: an atlas-based method and a sheetness-based method. We used Dice Similarity Coefficient (DSC) to measure the performances of the automated methods, with respect to the manual segmentations. Additionally, we computed Pearson's correlation between the breast density values computed based on manual and automated segmentations. The average DSC values for breast segmentation were 0.933, 0.944, 0.863, and 0.848 obtained from 3C U-net, 2C U-nets, atlas-based method, and sheetness-based method, respectively. The average DSC values for FGT segmentation obtained from 3C U-net, 2C U-nets, and atlas-based methods were 0.850, 0.811, and 0.671, respectively. The correlation between breast density values based on 3C U-net and manual segmentations was 0.974. This value was significantly higher than 0.957 as obtained from 2C U-nets (P < 0.0001, Steiger's Z-test with Bonferoni correction) and 0.938 as obtained from atlas-based method (P = 0.0016). In conclusion, we applied a deep-learning method, U-net, for segmenting breast and FGT in MRI in a dataset that includes a variety of MRI protocols and breast densities. Our results showed that U-net-based methods significantly outperformed the existing algorithms and resulted in significantly more accurate breast density computation."><meta property="og:image" content="https://geertlitjens.nl/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_512x512_fill_lanczos_center_3.png">
<meta property="twitter:image" content="https://geertlitjens.nl/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2017-02-01T00:00:00+00:00">
<meta property="article:modified_time" content="2017-02-01T00:00:00+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://geertlitjens.nl/publication/dalm-17/"},"headline":"Using deep learning to segment breast and fibroglandular tissue in MRI volumes","datePublished":"2017-02-01T00:00:00Z","dateModified":"2017-02-01T00:00:00Z","author":{"@type":"Person","name":"M. Dalmis"},"publisher":{"@type":"Organization","name":"Geert Litjens","logo":{"@type":"ImageObject","url":"https://geertlitjens.nl/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_192x192_fill_lanczos_center_3.png"}},"description":"Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer-aided applications of breast MRI. Traditional image analysis and computer vision techniques, such atlas, template matching, or, edge and surface detection, have been applied to solve this task. However, applicability of these methods is usually limited by the characteristics of the images used in the study datasets, while breast MRI varies with respect to the different MRI protocols used, in addition to the variability in breast shapes. All this variability, in addition to various MRI artifacts, makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore, in this study, we investigated the use of a deep-learning approach known as \"U-net.\" We used a dataset of 66 breast MRI's randomly selected from our scientific archive, which includes five different MRI acquisition protocols and breasts from four breast density categories in a balanced distribution. To prepare reference segmentations, we manually segmented breast and FGT for all images using an in-house developed workstation. We experimented with the application of U-net in two different ways for breast and FGT segmentation. In the first method, following the same pipeline used in traditional approaches, we trained two consecutive (2C) U-nets: first for segmenting the breast in the whole MRI volume and the second for segmenting FGT inside the segmented breast. In the second method, we used a single 3-class (3C) U-net, which performs both tasks simultaneously by segmenting the volume into three regions: nonbreast, fat inside the breast, and FGT inside the breast. For comparison, we applied two existing and published methods to our dataset: an atlas-based method and a sheetness-based method. We used Dice Similarity Coefficient (DSC) to measure the performances of the automated methods, with respect to the manual segmentations. Additionally, we computed Pearson's correlation between the breast density values computed based on manual and automated segmentations. The average DSC values for breast segmentation were 0.933, 0.944, 0.863, and 0.848 obtained from 3C U-net, 2C U-nets, atlas-based method, and sheetness-based method, respectively. The average DSC values for FGT segmentation obtained from 3C U-net, 2C U-nets, and atlas-based methods were 0.850, 0.811, and 0.671, respectively. The correlation between breast density values based on 3C U-net and manual segmentations was 0.974. This value was significantly higher than 0.957 as obtained from 2C U-nets (P \u003c 0.0001, Steiger's Z-test with Bonferoni correction) and 0.938 as obtained from atlas-based method (P = 0.0016). In conclusion, we applied a deep-learning method, U-net, for segmenting breast and FGT in MRI in a dataset that includes a variety of MRI protocols and breast densities. Our results showed that U-net-based methods significantly outperformed the existing algorithms and resulted in significantly more accurate breast density computation."}</script>
<title>Using deep learning to segment breast and fibroglandular tissue in MRI volumes | Geert Litjens</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=1c38ce9d7a91f33011019f96c1f512c6>
<script src=/js/wowchemy-init.min.b6ac29faab89ee14db88f0bed7aa6622.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Geert Litjens</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Geert Litjens</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#posts><span>Posts</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#media><span>Media</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#presentations><span>Presentations</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#publications><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#about><span>About</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/cv><span>CV</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>Using deep learning to segment breast and fibroglandular tissue in MRI volumes</h1>
<div class=article-metadata>
<div>
<span>
<a href=/authors/m.-dalmis/>M. Dalmis</a></span>, <span>
<a href=/authors/g.-litjens/>G. Litjens</a></span>, <span>
<a href=/authors/k.-holland/>K. Holland</a></span>, <span>
<a href=/authors/a.-setio/>A. Setio</a></span>, <span>
<a href=/authors/r.-mann/>R. Mann</a></span>, <span>
<a href=/authors/n.-karssemeijer/>N. Karssemeijer</a></span>, <span>
<a href=/authors/a.-gubern-merida/>A. Gubern-Mérida</a></span>
</div>
<span class=article-date>
February, 2017
</span>
</div>
<div class="btn-links mb-3">
<a class="btn btn-outline-primary btn-page-header" href=/publication/dalm-17/dalm-17.pdf target=_blank rel=noopener>
PDF
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.1002/mp.12079 target=_blank rel=noopener>
DOI
</a>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer-aided applications of breast MRI. Traditional image analysis and computer vision techniques, such atlas, template matching, or, edge and surface detection, have been applied to solve this task. However, applicability of these methods is usually limited by the characteristics of the images used in the study datasets, while breast MRI varies with respect to the different MRI protocols used, in addition to the variability in breast shapes. All this variability, in addition to various MRI artifacts, makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore, in this study, we investigated the use of a deep-learning approach known as &ldquo;U-net.&rdquo; We used a dataset of 66 breast MRI&rsquo;s randomly selected from our scientific archive, which includes five different MRI acquisition protocols and breasts from four breast density categories in a balanced distribution. To prepare reference segmentations, we manually segmented breast and FGT for all images using an in-house developed workstation. We experimented with the application of U-net in two different ways for breast and FGT segmentation. In the first method, following the same pipeline used in traditional approaches, we trained two consecutive (2C) U-nets: first for segmenting the breast in the whole MRI volume and the second for segmenting FGT inside the segmented breast. In the second method, we used a single 3-class (3C) U-net, which performs both tasks simultaneously by segmenting the volume into three regions: nonbreast, fat inside the breast, and FGT inside the breast. For comparison, we applied two existing and published methods to our dataset: an atlas-based method and a sheetness-based method. We used Dice Similarity Coefficient (DSC) to measure the performances of the automated methods, with respect to the manual segmentations. Additionally, we computed Pearson&rsquo;s correlation between the breast density values computed based on manual and automated segmentations. The average DSC values for breast segmentation were 0.933, 0.944, 0.863, and 0.848 obtained from 3C U-net, 2C U-nets, atlas-based method, and sheetness-based method, respectively. The average DSC values for FGT segmentation obtained from 3C U-net, 2C U-nets, and atlas-based methods were 0.850, 0.811, and 0.671, respectively. The correlation between breast density values based on 3C U-net and manual segmentations was 0.974. This value was significantly higher than 0.957 as obtained from 2C U-nets (P &lt; 0.0001, Steiger&rsquo;s Z-test with Bonferoni correction) and 0.938 as obtained from atlas-based method (P = 0.0016). In conclusion, we applied a deep-learning method, U-net, for segmenting breast and FGT in MRI in a dataset that includes a variety of MRI protocols and breast densities. Our results showed that U-net-based methods significantly outperformed the existing algorithms and resulted in significantly more accurate breast density computation.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#3>
Journal article
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9"><em>Med Phys</em></div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/mri-breast-segmentation-deep-learning/>MRI; breast segmentation; deep learning</a>
</div>
<div class=share-box>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://geertlitjens.nl/publication/dalm-17/&text=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://geertlitjens.nl/publication/dalm-17/&t=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes&body=https://geertlitjens.nl/publication/dalm-17/" target=_blank rel=noopener class=share-btn-email aria-label=envelope>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://geertlitjens.nl/publication/dalm-17/&title=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes%20https://geertlitjens.nl/publication/dalm-17/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://geertlitjens.nl/publication/dalm-17/&title=Using%20deep%20learning%20to%20segment%20breast%20and%20fibroglandular%20tissue%20in%20MRI%20volumes" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
© 2019
</p>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/bash.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.0cb61b39a43590bf7470ddb0caa9f812.js></script>
</body>
</html>
<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Geert Litjens">

  
  
  
    
  
  <meta name="description" content="This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0.">

  
  <link rel="alternate" hreflang="en-us" href="https://geertlitjens.nl/post/getting-started-with-camelyon/">

  


  
  
  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/vs2015.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/vs2015.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139145569-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-139145569-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://geertlitjens.nl/post/getting-started-with-camelyon/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@GeertLitjens">
  <meta property="twitter:creator" content="@GeertLitjens">
  
  <meta property="og:site_name" content="Geert Litjens">
  <meta property="og:url" content="https://geertlitjens.nl/post/getting-started-with-camelyon/">
  <meta property="og:title" content="Getting Started With Camelyon (Part 1) | Geert Litjens">
  <meta property="og:description" content="This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0."><meta property="og:image" content="https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png">
  <meta property="twitter:image" content="https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-04-24T13:41:43&#43;02:00">
    
    <meta property="article:modified_time" content="2019-04-24T13:41:43&#43;02:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://geertlitjens.nl/post/getting-started-with-camelyon/"
  },
  "headline": "Getting Started With Camelyon (Part 1)",
  
  "image": [
    "https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png"
  ],
  
  "datePublished": "2019-04-24T13:41:43+02:00",
  "dateModified": "2019-04-24T13:41:43+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Geert Litjens"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Geert Litjens",
    "logo": {
      "@type": "ImageObject",
      "url": "https://geertlitjens.nl/images/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0."
}
</script>

  

  


  


  





  <title>Getting Started With Camelyon (Part 1) | Geert Litjens</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="dark">

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Geert Litjens</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Geert Litjens</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#media"><span>Media</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#presentations"><span>Presentations</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/cv"><span>CV</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Getting Started With Camelyon (Part 1)</h1>

  

  
    



<meta content="2019-04-24 13:41:43 &#43;0200 &#43;0200" itemprop="datePublished">
<meta content="2019-04-24 13:41:43 &#43;0200 &#43;0200" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  
  <div>
    

  
  <span><a href="/authors/geert/">Geert Litjens</a></span>
  </div>
  
  

  <span class="article-date">
    
    
      
    
    <time>Apr 24, 2019</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  
  

  
  

  
    

  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>This is the first part of a three part tutorial on how to get started with the 
<a href="https://camelyon17.grand-challenge.org" target="_blank" rel="noopener">CAMELYON dataset</a>. This first part will focus on getting a basic convolutional neural network trained using 
<a href="https://github.com/basveeling/pcam" target="_blank" rel="noopener">PatchCAMELYON</a>, TensorFlow 2.0, Keras and TensorFlow Datasets. Part 2 will cover applying your trained model to a whole-slide image and visualizing the results and Part 3 will cover how to use the full dataset to train a model at different resolution levels, sampling strategies, and data augmentation.</p>
<p>To get started you need to setup a Python environment with NumPy, Matplotlib and TensorFlow 2.0. To use the PatchCAMELYON dataset with TensorFlow Datasets you will need to use my fork of the project for now as the pull request to add PatchCAMELYON to the master branch is not yet approved. To this end you need to do clone the repository and add it to your Python environment:</p>
<pre><code class="language-bash">git clone https://github.com/GeertLitjens/tensorflow_datasets
cd tensorflow_datasets
python setup.py develop
</code></pre>
<p>After this step you should be able to import the relevant packages with the following cell</p>
<pre><code class="language-python"># Import NumPy to handle array's and Matplotlib for plotting loss curves
import numpy as np
import matplotlib.pyplot as plt

# Import TensorFlow and relevant Keras classes to setup the model
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint
</code></pre>
<p>The next cell will automatically download PatchCAMELYON from Zenodo and prepare the TensorFlow Datasets</p>
<pre><code class="language-python">import tensorflow_datasets as tfds
pcam, pcam_info = tfds.load(&quot;patch_camelyon&quot;, with_info=True)
print(pcam_info)
</code></pre>
<blockquote>
<pre><code class="language-python"></code></pre>
</blockquote>
<pre><code>tfds.core.DatasetInfo(
    name='patch_camelyon',
    version=1.0.0,
    description='The PatchCAMELYON dataset for identification of breast cancer metastases in lymph nodes. This dataset has been extracted from the larger CAMELYON dataset of 1399 whole-slide images, which created for the CAMELYON challenges at ISBI 2016 and 2017.It contains 96x96 RGB patches of normal lymph node and tumor tissue in a roughly 50/50 distributions. It packs the clinically-relevant task of metastasis detection into a straight-forward image classification task, akin to CIFAR-10 and MNIST. This increases the ease of use by removing the complexity of handling large whole-slide images.',
    urls=['https://github.com/basveeling/pcam', 'https://camelyon17.grand-challenge.org/'],
    features=FeaturesDict({
        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2)
    },
    total_num_examples=327680,
    splits={
        'test': &lt;tfds.core.SplitInfo num_examples=32768&gt;,
        'train': &lt;tfds.core.SplitInfo num_examples=262144&gt;,
        'validation': &lt;tfds.core.SplitInfo num_examples=32768&gt;
    },
    supervised_keys=('image', 'label'),
    citation='&quot;&quot;&quot;
        @ARTICLE{Veeling2018-qh,
          title         = &quot;Rotation Equivariant {CNNs} for Digital Pathology&quot;,
          author        = &quot;Veeling, Bastiaan S and Linmans, Jasper and Winkens, Jim and
                           Cohen, Taco and Welling, Max&quot;,
          month         =  jun,
          year          =  2018,
          archivePrefix = &quot;arXiv&quot;,
          primaryClass  = &quot;cs.CV&quot;,
          eprint        = &quot;1806.03962&quot;
        }
        @article{Litjens2018,
            author = {Litjens, G. and Bándi, P. and Ehteshami Bejnordi, B. and Geessink, O. and Balkenhol, M. and Bult, P. and Halilovic, A. and Hermsen, M. and van de Loo, R. and Vogels, R. and Manson, Q.F. and Stathonikos, N. and Baidoshvili, A. and van Diest, P. and Wauters, C. and van Dijk, M. and van der Laak, J.},
            title = {1399 H&amp;E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset},
            journal = {GigaScience},
            volume = {7},
            number = {6},
            year = {2018},
            month = {05},
            issn = {2047-217X},
            doi = {10.1093/gigascience/giy065},
            url = {https://dx.doi.org/10.1093/gigascience/giy065},
            eprint = {http://oup.prod.sis.lan/gigascience/article-pdf/7/6/giy065/25045131/giy065.pdf},
        }
        
    &quot;&quot;&quot;',
    redistribution_info=,
)
</code></pre>
<pre><code>    

Now we have our dataset ready, it is time to define our model. The cell below defines a very simple VGG-like convolutional neural network using Keras.


```python
#First setup the input to the network which has the dimensions of the patches contained within PatchCAMELYON
input_img = Input(shape=(96,96,3))

# Now we define the layers of the convolutional network: three blocks of two convolutional layers and a max-pool layer.
x = Conv2D(16, (3, 3), padding='valid', activation='relu')(input_img)
x = Conv2D(16, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)
x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)
x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)
x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)
x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)

# Now we flatten the output from a 4D to a 2D tensor to be able to use fully-connected (dense) layers for the final
# classification part. Here we also use a bit of dropout for regularization. The last layer uses a softmax to obtain class
# likelihoods (i.e. metastasis vs. non-metastasis)
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(rate=0.2)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(rate=0.2)(x)
predictions = Dense(2, activation='softmax')(x)

# Now we define the inputs/outputs of the model and setup the optimizer. In this case we use regular stochastic gradient
# descent with Nesterov momentum. The loss we use is cross-entropy and we would like to output accuracy as an additional metric.
model = Model(inputs=input_img, outputs=predictions)
sgd_opt = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)
model.compile(optimizer=sgd_opt,
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()
</code></pre>
<blockquote>
<pre><code class="language-text"></code></pre>
</blockquote>
<p>Model: &ldquo;model&rdquo;</p>
<hr>
<h1 id="layer-type-----------------output-shape--------------param-">Layer (type)                 Output Shape              Param #</h1>
<p>input_1 (InputLayer)         [(None, 96, 96, 3)]       0</p>
<hr>
<p>conv2d (Conv2D)              (None, 94, 94, 16)        448</p>
<hr>
<p>conv2d_1 (Conv2D)            (None, 92, 92, 16)        2320</p>
<hr>
<p>max_pooling2d (MaxPooling2D) (None, 46, 46, 16)        0</p>
<hr>
<p>conv2d_2 (Conv2D)            (None, 44, 44, 32)        4640</p>
<hr>
<p>conv2d_3 (Conv2D)            (None, 42, 42, 32)        9248</p>
<hr>
<p>max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0</p>
<hr>
<p>conv2d_4 (Conv2D)            (None, 19, 19, 64)        18496</p>
<hr>
<p>conv2d_5 (Conv2D)            (None, 17, 17, 64)        36928</p>
<hr>
<p>max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0</p>
<hr>
<p>flatten (Flatten)            (None, 4096)              0</p>
<hr>
<p>dense (Dense)                (None, 256)               1048832</p>
<hr>
<p>dropout (Dropout)            (None, 256)               0</p>
<hr>
<p>dense_1 (Dense)              (None, 128)               32896</p>
<hr>
<p>dropout_1 (Dropout)          (None, 128)               0</p>
<hr>
<h1 id="dense_2-dense--------------none-2-----------------258">dense_2 (Dense)              (None, 2)                 258</h1>
<p>Total params: 1,154,066
Trainable params: 1,154,066
Non-trainable params: 0</p>
<hr>
<pre><code>
To keep the dataset size small PatchCAMELYON is stored as int8 patches. For network training we need float32 and we want to normalize between 0 and 1. The function below performs this task.


```python
def convert_sample(sample):
    image, label = sample['image'], sample['label']  
    image = tf.image.convert_image_dtype(image, tf.float32)
    label = tf.one_hot(label, 2, dtype=tf.float32)
    return image, label
</code></pre>
<p>Now we use the <code>tf.data</code> pipeline to apply this function to the dataset in a parallel fashion. We also shuffle the training data with a shuffle buffer (which is randomly filled with samples from the dataset) of 1024. Next we define batches of 64 patches for training and 128 for validation. Last, we prefetch 2 batches such that we can get batches during training on the GPU.</p>
<pre><code class="language-python">train_pipeline = pcam['train'].map(convert_sample,
                                   num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)
valid_pipeline = pcam['validation'].map(convert_sample,
                                        num_parallel_calls=8).repeat().batch(128).prefetch(2)
</code></pre>
<p>Now we just apply train and evaluate the model using our dataset pipeline. We pick the steps per epoch such that the entire training and validation set are covered each epoch. We keep the History object that <code>fit</code> returns to plot the loss progression later on. We now just do 5 epochs for illustration purposes. Feel free to experiment with the number of epochs. If you want to keep the best model during training you can use the Keras <code>ModelCheckpoint</code> callback to write each improvement to disk.</p>
<pre><code class="language-python">hist = model.fit(train_pipeline,
                 validation_data=valid_pipeline,
                 verbose=2, epochs=5, steps_per_epoch=4096, validation_steps=256)
</code></pre>
<blockquote>
<pre><code class="language-text"></code></pre>
</blockquote>
<p>Epoch 1/5
4096/4096 - 101s - loss: 0.6756 - accuracy: 0.5501 - val_loss: 0.5228 - val_accuracy:  0.7527
Epoch 2/5
4096/4096 - 98s - loss: 0.4292 - accuracy: 0.8071 - val_loss: 0.3946 - val_accuracy:  0.8249
Epoch 3/5
4096/4096 - 99s - loss: 0.3165 - accuracy: 0.8675 - val_loss: 0.3634 - val_accuracy:  0.8390
Epoch 4/5
4096/4096 - 100s - loss: 0.2586 - accuracy: 0.8958 - val_loss: 0.3707 - val_accuracy:  0.8340
Epoch 5/5
4096/4096 - 99s - loss: 0.2260 - accuracy: 0.9118 - val_loss: 0.3353 - val_accuracy:  0.8568</p>
<pre><code>
If we are happy with our performance on the validation set we can check whether it generalized to the test set. Note that it is bad practice to look at your test set performance too often; you will start making modification to your network/training procedure to optimize test set performance which results in optimistically biased performance estimates.


```python
test_pipeline = pcam['test'].map(convert_sample, num_parallel_calls=8).batch(128).prefetch(2)
print(&quot;Test set accuracy is {0:.4f}&quot;.format(model.evaluate(test_pipeline, steps=128, verbose=0)[1]))
</code></pre>
<blockquote>
<pre><code class="language-text"></code></pre>
</blockquote>
<p>Test set accuracy is 0.8563</p>
<pre><code>
If we are happy with the performance we can write the model to disk.


```python
model.save(&quot;./patchcamelyon.hf5&quot;)
</code></pre>
<p>If you followed along with all the steps you should get a test set performance between 0.8 and 0.87. Differences occur due to different weight initialization of the network for example. To make network training more reproducible you can specify the random seed for the weight initializers manually. Note that the training process cannot be fully deterministic due to backpropogation step in the CUDNN library not being deterministic. I hope you enjoyed this brief tutorial, the next post will be about how to use our saved model to classify a whole-slide image.</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">machine learning</a>
  
  <a class="badge badge-light" href="/tags/camelyon/">CAMELYON</a>
  
  <a class="badge badge-light" href="/tags/tutorial/">tutorial</a>
  
</div>













  
  
    
  
  






  
  
  
    
  




<section id="comments">
  
    <div id="commento"></div>

<script src="https://cdn.commento.io/js/commento.js" defer></script>

  
</section>






  
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/bash.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = true;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.6f7ce8be710290b8c431bbc97f405d15.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    © 2019 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>

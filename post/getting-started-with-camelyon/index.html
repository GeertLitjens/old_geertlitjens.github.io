<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<meta name=author content="Geert Litjens">
<meta name=description content="This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0.">
<link rel=alternate hreflang=en-us href=https://geertlitjens.nl/post/getting-started-with-camelyon/>
<meta name=theme-color content="hsl(339, 90%, 68%)">
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/vs2015.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/vs2015.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=/css/wowchemy.7d86dc42c902b14610813b0603567dae.css>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-139145569-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(a,b){gtag('event','click',{event_category:'outbound',event_label:a,transport_type:'beacon',event_callback:function(){b!=='_blank'&&(document.location=a)}}),console.debug("Outbound link clicked: "+a)}function onClickCallback(a){if(a.target.tagName!=='A'||a.target.host===window.location.host)return;trackOutboundLink(a.target,a.target.getAttribute('target'))}gtag('js',new Date),gtag('config','UA-139145569-1',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://geertlitjens.nl/post/getting-started-with-camelyon/>
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:site" content="@GeertLitjens">
<meta property="twitter:creator" content="@GeertLitjens">
<meta property="og:site_name" content="Geert Litjens">
<meta property="og:url" content="https://geertlitjens.nl/post/getting-started-with-camelyon/">
<meta property="og:title" content="Getting Started With Camelyon (Part 1) | Geert Litjens">
<meta property="og:description" content="This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0."><meta property="og:image" content="https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png">
<meta property="twitter:image" content="https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2019-04-24T13:41:43+02:00">
<meta property="article:modified_time" content="2019-04-24T13:41:43+02:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://geertlitjens.nl/post/getting-started-with-camelyon/"},"headline":"Getting Started With Camelyon (Part 1)","image":["https://geertlitjens.nl/post/getting-started-with-camelyon/featured.png"],"datePublished":"2019-04-24T13:41:43+02:00","dateModified":"2019-04-24T13:41:43+02:00","author":{"@type":"Person","name":"Geert Litjens"},"publisher":{"@type":"Organization","name":"Geert Litjens","logo":{"@type":"ImageObject","url":"https://geertlitjens.nl/media/icon_hue0c2058e8f722cf54419e3dfd4f45926_15543_192x192_fill_lanczos_center_3.png"}},"description":"This post is the first of a three post series on using deep learning to tackle the CAMELYON Challenge. This first post covers basic convolutional neural network training using the PatchCAMELYON dataset and TensorFlow 2.0."}</script>
<title>Getting Started With Camelyon (Part 1) | Geert Litjens</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=d91c943005e36a04aff38d3b3151fa95>
<script src=/js/wowchemy-init.min.b6ac29faab89ee14db88f0bed7aa6622.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Geert Litjens</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Geert Litjens</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#posts><span>Posts</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#media><span>Media</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#presentations><span>Presentations</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#publications><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#about><span>About</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/cv><span>CV</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<article class=article>
<div class="article-container pt-3">
<h1>Getting Started With Camelyon (Part 1)</h1>
<div class=article-metadata>
<span class=article-date>
Apr 24, 2019
</span>
<span class=middot-divider></span>
<span class=article-reading-time>
7 min read
</span>
</div>
</div>
<div class=article-container>
<div class=article-style>
<p>This is the first part of a three part tutorial on how to get started with the <a href=https://camelyon17.grand-challenge.org target=_blank rel=noopener>CAMELYON dataset</a>. This first part will focus on getting a basic convolutional neural network trained using <a href=https://github.com/basveeling/pcam target=_blank rel=noopener>PatchCAMELYON</a>, TensorFlow 2.0, Keras and TensorFlow Datasets. Part 2 will cover applying your trained model to a whole-slide image and visualizing the results and Part 3 will cover how to use the full dataset to train a model at different resolution levels, sampling strategies, and data augmentation.</p>
<p>To get started you need to setup a Python environment with NumPy, Matplotlib and TensorFlow 2.0. To use the PatchCAMELYON dataset with TensorFlow Datasets you will need to use my fork of the project for now as the pull request to add PatchCAMELYON to the master branch is not yet approved. To this end you need to do clone the repository and add it to your Python environment:</p>
<pre><code class=language-bash>git clone https://github.com/GeertLitjens/tensorflow_datasets
cd tensorflow_datasets
python setup.py develop
</code></pre>
<p>After this step you should be able to import the relevant packages with the following cell</p>
<pre><code class=language-python># Import NumPy to handle array's and Matplotlib for plotting loss curves
import numpy as np
import matplotlib.pyplot as plt

# Import TensorFlow and relevant Keras classes to setup the model
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint
</code></pre>
<p>The next cell will automatically download PatchCAMELYON from Zenodo and prepare the TensorFlow Datasets</p>
<pre><code class=language-python>import tensorflow_datasets as tfds
pcam, pcam_info = tfds.load(&quot;patch_camelyon&quot;, with_info=True)
print(pcam_info)
</code></pre>
<blockquote>
<pre><code class=language-python></code></pre>
</blockquote>
<pre><code>tfds.core.DatasetInfo(
    name='patch_camelyon',
    version=1.0.0,
    description='The PatchCAMELYON dataset for identification of breast cancer metastases in lymph nodes. This dataset has been extracted from the larger CAMELYON dataset of 1399 whole-slide images, which created for the CAMELYON challenges at ISBI 2016 and 2017.It contains 96x96 RGB patches of normal lymph node and tumor tissue in a roughly 50/50 distributions. It packs the clinically-relevant task of metastasis detection into a straight-forward image classification task, akin to CIFAR-10 and MNIST. This increases the ease of use by removing the complexity of handling large whole-slide images.',
    urls=['https://github.com/basveeling/pcam', 'https://camelyon17.grand-challenge.org/'],
    features=FeaturesDict({
        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2)
    },
    total_num_examples=327680,
    splits={
        'test': &lt;tfds.core.SplitInfo num_examples=32768&gt;,
        'train': &lt;tfds.core.SplitInfo num_examples=262144&gt;,
        'validation': &lt;tfds.core.SplitInfo num_examples=32768&gt;
    },
    supervised_keys=('image', 'label'),
    citation='&quot;&quot;&quot;
        @ARTICLE{Veeling2018-qh,
          title         = &quot;Rotation Equivariant {CNNs} for Digital Pathology&quot;,
          author        = &quot;Veeling, Bastiaan S and Linmans, Jasper and Winkens, Jim and
                           Cohen, Taco and Welling, Max&quot;,
          month         =  jun,
          year          =  2018,
          archivePrefix = &quot;arXiv&quot;,
          primaryClass  = &quot;cs.CV&quot;,
          eprint        = &quot;1806.03962&quot;
        }
        @article{Litjens2018,
            author = {Litjens, G. and Bándi, P. and Ehteshami Bejnordi, B. and Geessink, O. and Balkenhol, M. and Bult, P. and Halilovic, A. and Hermsen, M. and van de Loo, R. and Vogels, R. and Manson, Q.F. and Stathonikos, N. and Baidoshvili, A. and van Diest, P. and Wauters, C. and van Dijk, M. and van der Laak, J.},
            title = {1399 H&amp;E-stained sentinel lymph node sections of breast cancer patients: the CAMELYON dataset},
            journal = {GigaScience},
            volume = {7},
            number = {6},
            year = {2018},
            month = {05},
            issn = {2047-217X},
            doi = {10.1093/gigascience/giy065},
            url = {https://dx.doi.org/10.1093/gigascience/giy065},
            eprint = {http://oup.prod.sis.lan/gigascience/article-pdf/7/6/giy065/25045131/giy065.pdf},
        }
        
    &quot;&quot;&quot;',
    redistribution_info=,
)
</code></pre>
<pre><code>    

Now we have our dataset ready, it is time to define our model. The cell below defines a very simple VGG-like convolutional neural network using Keras.


```python
#First setup the input to the network which has the dimensions of the patches contained within PatchCAMELYON
input_img = Input(shape=(96,96,3))

# Now we define the layers of the convolutional network: three blocks of two convolutional layers and a max-pool layer.
x = Conv2D(16, (3, 3), padding='valid', activation='relu')(input_img)
x = Conv2D(16, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)
x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)
x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)
x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)
x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)
x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)

# Now we flatten the output from a 4D to a 2D tensor to be able to use fully-connected (dense) layers for the final
# classification part. Here we also use a bit of dropout for regularization. The last layer uses a softmax to obtain class
# likelihoods (i.e. metastasis vs. non-metastasis)
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(rate=0.2)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(rate=0.2)(x)
predictions = Dense(2, activation='softmax')(x)

# Now we define the inputs/outputs of the model and setup the optimizer. In this case we use regular stochastic gradient
# descent with Nesterov momentum. The loss we use is cross-entropy and we would like to output accuracy as an additional metric.
model = Model(inputs=input_img, outputs=predictions)
sgd_opt = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)
model.compile(optimizer=sgd_opt,
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()
</code></pre>
<blockquote>
<pre><code class=language-text></code></pre>
</blockquote>
<p>Model: &ldquo;model&rdquo;</p>
<hr>
<h1 id=layer-type-----------------output-shape--------------param->Layer (type) Output Shape Param #</h1>
<p>input_1 (InputLayer) [(None, 96, 96, 3)] 0</p>
<hr>
<p>conv2d (Conv2D) (None, 94, 94, 16) 448</p>
<hr>
<p>conv2d_1 (Conv2D) (None, 92, 92, 16) 2320</p>
<hr>
<p>max_pooling2d (MaxPooling2D) (None, 46, 46, 16) 0</p>
<hr>
<p>conv2d_2 (Conv2D) (None, 44, 44, 32) 4640</p>
<hr>
<p>conv2d_3 (Conv2D) (None, 42, 42, 32) 9248</p>
<hr>
<p>max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32) 0</p>
<hr>
<p>conv2d_4 (Conv2D) (None, 19, 19, 64) 18496</p>
<hr>
<p>conv2d_5 (Conv2D) (None, 17, 17, 64) 36928</p>
<hr>
<p>max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64) 0</p>
<hr>
<p>flatten (Flatten) (None, 4096) 0</p>
<hr>
<p>dense (Dense) (None, 256) 1048832</p>
<hr>
<p>dropout (Dropout) (None, 256) 0</p>
<hr>
<p>dense_1 (Dense) (None, 128) 32896</p>
<hr>
<p>dropout_1 (Dropout) (None, 128) 0</p>
<hr>
<h1 id=dense_2-dense--------------none-2-----------------258>dense_2 (Dense) (None, 2) 258</h1>
<p>Total params: 1,154,066
Trainable params: 1,154,066
Non-trainable params: 0</p>
<hr>
<pre><code>
To keep the dataset size small PatchCAMELYON is stored as int8 patches. For network training we need float32 and we want to normalize between 0 and 1. The function below performs this task.


```python
def convert_sample(sample):
    image, label = sample['image'], sample['label']  
    image = tf.image.convert_image_dtype(image, tf.float32)
    label = tf.one_hot(label, 2, dtype=tf.float32)
    return image, label
</code></pre>
<p>Now we use the <code>tf.data</code> pipeline to apply this function to the dataset in a parallel fashion. We also shuffle the training data with a shuffle buffer (which is randomly filled with samples from the dataset) of 1024. Next we define batches of 64 patches for training and 128 for validation. Last, we prefetch 2 batches such that we can get batches during training on the GPU.</p>
<pre><code class=language-python>train_pipeline = pcam['train'].map(convert_sample,
                                   num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)
valid_pipeline = pcam['validation'].map(convert_sample,
                                        num_parallel_calls=8).repeat().batch(128).prefetch(2)
</code></pre>
<p>Now we just apply train and evaluate the model using our dataset pipeline. We pick the steps per epoch such that the entire training and validation set are covered each epoch. We keep the History object that <code>fit</code> returns to plot the loss progression later on. We now just do 5 epochs for illustration purposes. Feel free to experiment with the number of epochs. If you want to keep the best model during training you can use the Keras <code>ModelCheckpoint</code> callback to write each improvement to disk.</p>
<pre><code class=language-python>hist = model.fit(train_pipeline,
                 validation_data=valid_pipeline,
                 verbose=2, epochs=5, steps_per_epoch=4096, validation_steps=256)
</code></pre>
<blockquote>
<pre><code class=language-text></code></pre>
</blockquote>
<p>Epoch 1/5
4096/4096 - 101s - loss: 0.6756 - accuracy: 0.5501 - val_loss: 0.5228 - val_accuracy: 0.7527
Epoch 2/5
4096/4096 - 98s - loss: 0.4292 - accuracy: 0.8071 - val_loss: 0.3946 - val_accuracy: 0.8249
Epoch 3/5
4096/4096 - 99s - loss: 0.3165 - accuracy: 0.8675 - val_loss: 0.3634 - val_accuracy: 0.8390
Epoch 4/5
4096/4096 - 100s - loss: 0.2586 - accuracy: 0.8958 - val_loss: 0.3707 - val_accuracy: 0.8340
Epoch 5/5
4096/4096 - 99s - loss: 0.2260 - accuracy: 0.9118 - val_loss: 0.3353 - val_accuracy: 0.8568</p>
<pre><code>
If we are happy with our performance on the validation set we can check whether it generalized to the test set. Note that it is bad practice to look at your test set performance too often; you will start making modification to your network/training procedure to optimize test set performance which results in optimistically biased performance estimates.


```python
test_pipeline = pcam['test'].map(convert_sample, num_parallel_calls=8).batch(128).prefetch(2)
print(&quot;Test set accuracy is {0:.4f}&quot;.format(model.evaluate(test_pipeline, steps=128, verbose=0)[1]))
</code></pre>
<blockquote>
<pre><code class=language-text></code></pre>
</blockquote>
<p>Test set accuracy is 0.8563</p>
<pre><code>
If we are happy with the performance we can write the model to disk.


```python
model.save(&quot;./patchcamelyon.hf5&quot;)
</code></pre>
<p>If you followed along with all the steps you should get a test set performance between 0.8 and 0.87. Differences occur due to different weight initialization of the network for example. To make network training more reproducible you can specify the random seed for the weight initializers manually. Note that the training process cannot be fully deterministic due to backpropogation step in the CUDNN library not being deterministic. I hope you enjoyed this brief tutorial, the next post will be about how to use our saved model to classify a whole-slide image.</p>
</div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/camelyon/>CAMELYON</a>
<a class="badge badge-light" href=/tag/machine-learning/>machine learning</a>
<a class="badge badge-light" href=/tag/tutorial/>tutorial</a>
</div>
<div class=share-box>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://geertlitjens.nl/post/getting-started-with-camelyon/&text=Getting%20Started%20With%20Camelyon%20%28Part%201%29" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://geertlitjens.nl/post/getting-started-with-camelyon/&t=Getting%20Started%20With%20Camelyon%20%28Part%201%29" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=Getting%20Started%20With%20Camelyon%20%28Part%201%29&body=https://geertlitjens.nl/post/getting-started-with-camelyon/" target=_blank rel=noopener class=share-btn-email aria-label=envelope>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://geertlitjens.nl/post/getting-started-with-camelyon/&title=Getting%20Started%20With%20Camelyon%20%28Part%201%29" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=Getting%20Started%20With%20Camelyon%20%28Part%201%29%20https://geertlitjens.nl/post/getting-started-with-camelyon/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://geertlitjens.nl/post/getting-started-with-camelyon/&title=Getting%20Started%20With%20Camelyon%20%28Part%201%29" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<section id=comments>
<div id=disqus_thread></div>
<script>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var b=document,a=b.createElement('script');a.async=!0,a.src='https://geertlitjens.disqus.com/embed.js',a.setAttribute('data-timestamp',+new Date),(b.head||b.body).appendChild(a)})()</script>
<noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript>
<a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a>
</section>
<div class="article-widget content-widget-hr">
<h3>Related</h3>
<ul>
<li><a href=/talk/intro-deep-learning/>Introduction to Deep Learning in Medical Imaging</a></li>
<li><a href=/project/camelyon/>CAMELYON</a></li>
<li><a href=/project/deeppca/>Deep PCa</a></li>
<li><a href=/project/deepderma/>DeepDerma</a></li>
</ul>
</div>
</div>
</article>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
© 2019
</p>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/bash.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.0cb61b39a43590bf7470ddb0caa9f812.js></script>
</body>
</html>